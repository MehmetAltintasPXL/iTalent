<!DOCTYPE html>
<html lang="nl">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title data-i18n="hackthefuture_title">Hack the Future</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header>
    <nav>
      <ul>
        <li><a href="index.html" data-i18n="home">Home</a></li>
        <li><a href="about.html" data-i18n="about">Over</a></li>
        <li><a href="contact.html" data-i18n="contact">Contact</a></li>
      </ul>
    </nav>
  </header>
  <main>
    <h1 data-i18n="hackthefuture_title">Hack the Future</h1>
    <p data-i18n="hackthefuture_desc">Hackathon georganiseerd door Cronos Groep met focus op integratie en AWS.</p>
    <p><em data-i18n="hackthefuture_time">Cronos Groep, Kontich – 19 november 2024, 08:00 - 21:00</em></p>
    <section>
      <h2 data-i18n="hackthefuture_reflection_title">Reflectie / Reflection</h2>
      <div data-i18n="hackthefuture_reflection_nl" lang="nl">
        Tijdens de jaarlijkse hackathon Hack The Future 2024 nam ik, samen met Quinten Cosemans, deel aan de cloud-challenge Are there clouds among the stars?. We vormden het team Hack Tuah en kregen vijf uitdagende opdrachten rondom AWS-diensten, externe APIs en het creëren van een geautomatiseerde workflow. Mijn persoonlijke doelstelling was om mijn technische kennis van serverless architecturen, API-integratie en cloudtoepassingen te verdiepen, en om onder hoge druk samen te werken aan een haalbare, innovatieve oplossing. Daarnaast wilde ik mijn probleemoplossend vermogen en communicatieve vaardigheden verfijnen, zodat ik de opgedane kennis rechtstreeks kon toepassen in latere projecten of stages.
        De hackathon Hack The Future 2024 was opgezet als een ruimtevaart-scenario waarin elke opdracht of level stap voor stap meer cloudintegratie en automatisatie vereiste. Het doel was om naadloos een reeks AWS-diensten en externe services te gebruiken, zodat we uiteindelijk een volledig geautomatiseerd en veilig systeem zouden hebben. Hoewel de tijdsdruk hoog was, ben ik er trots op hoe we als team onze taken hebben verdeeld en elk level hebben voltooid.
        Level 1 draaide rond het ontvangen en decoderen van een morsebericht via EventBridge. De ‘Mothership’ verstuurde periodiek een geminimaliseerd, gecodeerd bericht dat we via een Lambda-functie moesten opvangen en decoderen. Het was voor mij een interessante uitdaging om in Node.js een script te schrijven dat moeiteloos morsecode omzet in gewone tekst. Vervolgens stuurden we deze tekst door naar onze Discord-teamchat via een webhook. Op die manier kregen mijn teamgenoten en ik direct een melding van wat de Mothership doorstuurde. Dit eerste level leek eenvoudig, maar bleek heel waardevol voor het begrijpen van de dynamiek tussen EventBridge, Lambda en externe webhooks.
        Level 2 bouwde hierop voort en introduceerde GraphQL. We moesten bij de SpaceX GraphQL-endpoint informatie over lanceer- en landplatformen ophalen en die via JSON doorsturen naar de ‘Mothership’. Aangezien GraphQL nieuw was voor mij, moest ik snel schakelen en uitzoeken hoe ik met één enkele query meerdere datasets kon opvragen. Uiteindelijk konden we met één request zowel de launchpads als de landpads inlezen. We schreven een Lambda-functie die de resultaten in het juiste JSON-formaat goot en doorstuurde via een API-endpoint dat ons team had ingesteld. Dit level daagde ons uit om data gestructureerd te verzamelen en te valideren, zodat de ‘Mothership’ alle info correct kon opslaan.
        Level 3 introduceerde een volledig ander scenario: we moesten bestanden over ruimteweer van de NOAA-server ophalen via FTP. FTP was voor mij vrij onbekend in combinatie met moderne cloudservices, maar met wat onderzoek kwam ik erachter hoe ik dit proces kon automatiseren. De Lambda-functie doorzocht dagelijks de FTP-directory voor het meest recente bestand, hernoemde het naar datum+teamnaam, en uploadde het naar onze S3-bucket. Dit level wees me op het belang van zorgvuldig foutafhandeling en logging in te bouwen: rate limits, verbindingsfouten en trage responstijden zorgden voor een onvoorspelbare omgeving. Dankzij grondige testing en retries slaagden we er toch in het bestand consequent te downloaden en in S3 op te slaan.
        Level 4 bracht NASA’s “Picture of the Day” in het spel. Met een eigen API-key haalden we dagelijks de benodigde gegevens op, lazen we het bijhorende afbeeldingsbestand uit en verstuurden we het naar een tijdelijke mailbox via een e-mailservice in Node.js. Domme pech was dat e-mails soms niet aankwamen door verificatie-issues, maar we omzeilden dit door gebruik te maken van TempMail. Zo kregen we een werkende oplossing die elke ochtend de foto in onze mailbox afleverde, wat een leuke speelse invulling gaf aan het cloudluik. Dit level vereiste goed begrip van asynchrone processen en het correct doorgeven van bestanden over verschillende services heen.
        Level 5 was verreweg het meest geavanceerde onderdeel: we verwerkten de ruimteweerbestanden van NOAA in combinatie met de Gemini AI API. Na het binnenhalen van een bestand uit S3, analyseerde Gemini AI of de weersomstandigheden veilig waren voor ruimtereizen. Op basis van dit resultaat maakten we automatisch een taak aan in ClickUp in de kolom “Ready for departure” of “Not ready for departure”. Deze automatische beslissing betekende dat we AI-output moesten parsen en vertalen naar een concrete actie in ClickUp. Hier zaten veel valkuilen: rate limiting, authenticatie met tokens en het correct interpreteren van AI-resultaten. Toch slaagden we erin om het hele proces te laten draaien zonder manuele interventie, waardoor dit een mooi voorbeeld werd van een echte end-to-end automatisatie binnen AWS en externe services.
        Tot slot ontdekten we dat de organisatoren de S3-buckets te ruim hadden geconfigureerd, waardoor andere teams onze code konden inzien. Via onze Discord-notificaties merkten we dat meerdere partijen schaamteloos de code kopieerden zonder zelfs maar variabelen aan te passen. Desondanks slaagden we er als eerste in om alle levels correct af te ronden. We werden bekroond tot winnaars en ontvingen een muziekspeler met het Hack The Future-logo. Deze prestatie was niet alleen een bevestiging van ons harde werk, maar ook van onze aanpak om snel, efficiënt en creatief te reageren op problemen. Achteraf werden we zelfs benaderd door een bedrijf dat onze technische skills interessant vond voor een toekomstige samenwerking.
        Deze hackathonervaring heeft mijn vertrouwen in het werken met AWS en externe APIs enorm vergroot. Ik heb gemerkt dat mijn persoonlijke leerpunten vooral draaiden om het soepel integreren van uiteenlopende technologieën, het correct hanteren van diverse authenticatiemethoden en het doorgronden van nieuwe concepten zoals GraphQL en AI-integratie. De onderliggende principes zoals event-driven architectuur, het belang van goede error-handling en het correct structureren van data blijken universeel toepasbaar, zowel in toekomstige projecten als in professionele omgevingen.
        Wat ik vooral meeneem, is het belang van goede werkverdeling en communicatie binnen het team. Quinten en ik hadden een duidelijke taakopdeling gemaakt: ik richtte me op de automatisatie en scripting van Lambda-functies, terwijl hij zich focuste op configuraties en GraphQL-oproepen. Deze samenwerking verliep heel soepel, maar toch merkten we dat er af en toe overlap was in onze code, bijvoorbeeld bij het maken van webhooks en het aanroepen van externe APIs. We hebben geleerd om op tijd te overleggen, stukken code consistent te documenteren en testmomenten in te bouwen. Op die manier kwamen we minder snel voor verrassingen te staan.
        De onverwachte situatie waarin andere teams onze code kopieerden, maakte me ook bewust van de veiligheidsaspecten en het belang van het beveiligen van S3-buckets. Hoewel dit voor ons uiteindelijk een voordeel bleek we zagen meteen dat er misbruik werd gemaakt is dit in een echte productieomgeving onaanvaardbaar. Ik besef nu dat security niet enkel draait om sterke wachtwoorden, maar ook om het juist configureren van toegangsrechten en monitoring.
        Deze ervaring sluit goed aan op de vakken die ik volg in mijn opleiding, vooral op het gebied van cloud, security en softwareontwikkeling. De hackathon was niet alleen een technische test, maar ook een oefening in stressbestendigheid, flexibiliteit en creatief denken. Ik koos deze activiteit voor mijn portfolio omdat het aantoont hoe ik onder hoge druk technische uitdagingen kan aangaan, en omdat ik hieruit nieuwe inzichten en betere samenwerkingsvaardigheden heb verworven. Ik ben er trots op dat ik dankzij deze ervaring niet alleen ben gegroeid als developer, maar ook als teamspeler en probleemoplosser.
      </div>
      <div data-i18n="hackthefuture_reflection_en" lang="en">
        During the annual Hack The Future 2024 hackathon, I participated with Quinten Cosemans in the cloud challenge "Are there clouds among the stars?". We formed team Hack Tuah and tackled five challenging assignments involving AWS services, external APIs, and creating an automated workflow. My personal goal was to deepen my technical knowledge of serverless architectures, API integration, and cloud applications, and to collaborate under pressure on a feasible, innovative solution. I also wanted to refine my problem-solving and communication skills so I could apply the knowledge gained directly in future projects or internships.
        The Hack The Future 2024 hackathon was set up as a space scenario, where each assignment or level required progressively more cloud integration and automation. The goal was to seamlessly use a range of AWS services and external APIs, ultimately building a fully automated and secure system. Despite the time pressure, I am proud of how we divided our tasks as a team and completed each level.
        Level 1 was about receiving and decoding a Morse message via EventBridge. The 'Mothership' periodically sent a minimized, encoded message that we had to capture and decode using a Lambda function. It was an interesting challenge for me to write a Node.js script that could effortlessly convert Morse code into plain text. We then forwarded this text to our Discord team chat via a webhook, so my teammates and I received instant notifications of what the Mothership sent. This first level seemed simple but was very valuable for understanding the dynamics between EventBridge, Lambda, and external webhooks.
        Level 2 built on this and introduced GraphQL. We had to fetch information about launch and landing pads from the SpaceX GraphQL endpoint and send it as JSON to the 'Mothership'. Since GraphQL was new to me, I had to quickly figure out how to query multiple datasets in a single request. Eventually, we managed to retrieve both launchpads and landpads with one query. We wrote a Lambda function that formatted the results into the correct JSON and sent it via an API endpoint set up by our team. This level challenged us to collect and validate data in a structured way so the Mothership could store all info correctly.
        Level 3 introduced a completely different scenario: we had to fetch space weather files from the NOAA server via FTP. FTP was quite unfamiliar to me in combination with modern cloud services, but with some research, I figured out how to automate this process. The Lambda function searched the FTP directory daily for the latest file, renamed it to date+teamname, and uploaded it to our S3 bucket. This level taught me the importance of careful error handling and logging: rate limits, connection errors, and slow response times made for an unpredictable environment. Thanks to thorough testing and retries, we managed to consistently download the file and store it in S3.
        Level 4 brought NASA's "Picture of the Day" into play. With our own API key, we fetched the required data daily, read the associated image file, and sent it to a temporary mailbox via an email service in Node.js. Sometimes emails didn't arrive due to verification issues, but we worked around this by using TempMail. This gave us a working solution that delivered the photo to our mailbox every morning, adding a playful touch to the cloud aspect. This level required a good understanding of asynchronous processes and correctly passing files between different services.
        Level 5 was by far the most advanced part: we processed the NOAA space weather files in combination with the Gemini AI API. After retrieving a file from S3, Gemini AI analyzed whether the weather conditions were safe for space travel. Based on this result, we automatically created a task in ClickUp in the column "Ready for departure" or "Not ready for departure". This automatic decision meant we had to parse AI output and translate it into a concrete action in ClickUp. There were many pitfalls: rate limiting, token authentication, and correctly interpreting AI results. Still, we managed to get the whole process running without manual intervention, making this a great example of true end-to-end automation within AWS and external services.
        Finally, we discovered that the organizers had configured the S3 buckets too openly, allowing other teams to view our code. Through our Discord notifications, we noticed that several parties shamelessly copied our code without even changing variable names. Nevertheless, we were the first to complete all levels correctly. We were crowned winners and received a music player with the Hack The Future logo. This achievement was not only a confirmation of our hard work but also of our approach to respond quickly, efficiently, and creatively to problems. Afterwards, we were even approached by a company interested in our technical skills for future collaboration.
        This hackathon experience greatly increased my confidence in working with AWS and external APIs. I found that my personal learning points mainly revolved around smoothly integrating diverse technologies, correctly handling various authentication methods, and understanding new concepts like GraphQL and AI integration. Underlying principles such as event-driven architecture, the importance of good error handling, and proper data structuring are universally applicable, both in future projects and in professional environments.
        What I take away most is the importance of good task division and communication within the team. Quinten and I had a clear division of tasks: I focused on automation and scripting Lambda functions, while he focused on configurations and GraphQL queries. This collaboration went very smoothly, but we did notice some overlap in our code at times, for example when creating webhooks and calling external APIs. We learned to consult in time, consistently document code, and build in test moments. This way, we were less likely to be surprised.
        The unexpected situation where other teams copied our code also made me aware of security aspects and the importance of securing S3 buckets. Although this ultimately worked to our advantage, we immediately saw that abuse was taking place, which is unacceptable in a real production environment. I now realize that security is not just about strong passwords, but also about properly configuring access rights and monitoring.
        This experience fits well with the courses I am taking in my studies, especially in the areas of cloud, security, and software development. The hackathon was not only a technical test but also an exercise in stress resistance, flexibility, and creative thinking. I chose this activity for my portfolio because it shows how I can tackle technical challenges under high pressure and because I gained new insights and better collaboration skills from it. I am proud that, thanks to this experience, I have grown not only as a developer but also as a team player and problem solver.
      </div>
    </section>
    <a href="italent-hackathon.html" data-i18n="back_hackathon">← Terug naar Hackathon overzicht</a>
  </main>
  <footer>
    <p>&copy; 2024 Hack the Future. Alle rechten voorbehouden.</p>
  </footer>
  <script src="main.js"></script>
</body>
</html>